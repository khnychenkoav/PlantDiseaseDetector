## Классификация заболеваний растений с использованием ResNet50

### 1) Набор данных

- **Источник**: New Plant Diseases Dataset (Augmented)
- **Структура**:
    - 38 классов растений с различными заболеваниями и здоровыми образцами
    - Тренировочный набор: 70,295 изображений
    - Валидационный набор: 17,572 изображений


### 2) Предобработка данных

**Фильтрация**:

1. Применение Gaussian Blur (ядро 5x5)
2. Увеличение резкости с помощью ядра:
```
[[ 0, -1,  0],
 [-1,  5, -1],
 [ 0, -1,  0]]
```

**Общие преобразования**:

- Измение размерности до 224x224 пикселей
- Нормализация:
    - Средние: [0.485, 0.456, 0.406]
    - Стандартные отклонения: [0.229, 0.224, 0.225]

**Аугментация для тренировки**:

- Случайное горизонтальное отражение
- Случайный поворот (±30°)


### 3) Генерация потоков данных

- **DataLoader**:
    - Размер батча: 32
    - Параллельная загрузка: 4 workers
    - Shuffle: только для тренировочного набора

```python
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)
```


### 4) Архитектура модели

**Основа**: ResNet50 (предобученная на ImageNet)

- **Модификации**:
    - Замена последнего полносвязного слоя под 38 классов
    - Адаптация под GPU через `.to(device)`

**Конфигурация обучения**:

- Оптимизатор: Adam (по умолчанию)
- Функция потерь: CrossEntropyLoss
- Метрика: Accuracy


### 5) Обоснование выбора

1. **Transfer Learning**:
    - ResNet50 показывает SOTA результаты в классификации изображений
    - Предобученные веса ускоряют сходимость модели
2. **Аугментация**:
    - Компенсирует ограниченный размер датасета
    - Повышает устойчивость к вариациям в условиях съемки
3. **Препроцессинг**:
    - Gaussian Blur уменьшает шумы
    - Увеличение резкости подчеркивает детали листьев
    - Нормализация улучшает стабильность обучения
4. **Аппаратная оптимизация**:
    - Использование CUDA для ускорения вычислений
    - Параллельная загрузка данных (num_workers=4)


### 6) Анализ работы с моделью в рамках этого проекта

Практическая часть работы заключается в применении модели ResNet50 для автоматической
классификации болезней растений по изображениям листьев. В эксперименте использовался
датасет PlantVillage (и его расширенная версия с аугментациями) – один из наиболеераспространенных наборов данных, включающий фотографии листьев 38 классов (разных
культур и заболеваний, плюс здоровые листья) на однородном фоне. 
Каждое изображение
имеет метку вида "Культура___Болезнь" (например, Apple___Black_rot – черная гниль яблони).
Данные были разделены на обучающую и тестовую выборки; для контроля качества часть
обучающих данных использовалась в качестве валидационной выборки.
Выполним обучение в течение нескольких эпох, оценивая качество на
валидационном наборе после каждой эпохи. В ходе обучения будем вычислять метрики
точности, precision, recall и F1-score для более полного анализа (для мультиклассовой задачи эти
метрики обычно усредняются по классам).
При обучении мы уменьшали коэффициент обучения (learning rate) после 8-й эпохи в 10 раз для
более тонкой настройки модели. Выходы обучения показывают, что уже за несколько эпох
точность резко выросла, а к 12-й эпохе модель почти полностью обучилась.
Как видно, за 12 эпох точность на валидации достигла ~99%, а F1-score ~0.99, то есть модель
практически идеально научилась распознавать болезни на отложенной выборке, состоящей из
таких же по распределению изображений. Наблюдается небольшой перелучение (overfitting):
точность на трейне стремится к 100%, но и на валидации удерживается около 99%, что
свидетельствует о высокой обобщающей способности в рамках этого датасета. Однако, как мы
обсуждали, на данных с других распределений (полевых) качество будет ниже.
На графиках видно, что по мере обучения Loss на трейне стремительно падает и к ~8
эпохе выходит на плато, аналогично и на валидации (при этом валид. loss всегда ниже
тренингового, т.к. на трейне применены data augmentation, усложняющие задачу). Accuracy
(точность классификации) растет с каждой эпохой, приближаясь к 100%. Метрики Precision, Recall
и F1-score также растут и сходятся к ~0.98–0.99, практически сливаясь – это значит, что модель
сбалансированно обучилась по всем классам, не жертвуя одним метрикам ради других.
После обучения модель была протестирована на независимом тестовом наборе изображений
(листья, не участвовавшие в обучении и валидации). На тесте получены сходные интегральные
метрики – точность около 99%. Для более детального анализа ошибок построена матрица
ошибок (confusion matrix).
Зеленый цвет соответствует нулю ошибок, синий – к максимальному числу (500) на диагонали.
Как видно, матрица практически диагональна – модель правильно классифицировала
подавляющее большинство примеров во всех 38 классах. Диагональные элементы (от 418 до 502)
– это количество верно распознанных изображений каждого класса (в тесте примерно по 500 шт.
на класс). Вне диагонали встречаются лишь единичные ошибки (значения 1–5, обозначенные
светло-зеленым). Например, класс 7 модель путала 1 раз с классом 8, класс 13 – пару раз с классом
12, и т.д. Ни одного класса, где накопились бы десятки ошибок, не наблюдается. Это
подтверждает, что для контролируемых изображений (схожих с обучающими) ResNet50
способна надёжно дифференцировать симптомы всех болезней.
При оценке моделей классификации обычно используются следующие основные метрики:
• Accuracy (точность) – доля правильно классифицированных примеров ко всему набору. В
нашем эксперименте Accuracy на контролируемом тестовом наборе достигла ~0.99 (99%).
Однако accuracy может быть завышена при сильном дисбалансе классов, поэтому ее стоит
рассматривать вместе с другими показателями.
• Precision (точность прогнозирования) – доля верных положительных предсказаний
среди всех положительных предсказаний модели для класса. Грубо говоря, если модель
говорит "это болезнь X", то precision показывает, как часто она оказывается права.
Высокий precision важен, чтобы не было ложных тревог (false positives) – в контексте
агродиагностики это означает, что модель редко будет "паниковать" и ошибочно
диагностировать болезнь там, где ее нет.
• Recall (полнота) – доля верно предсказанных случаев класса среди всех реальных случаев
этого класса. То есть насколько хорошо модель находит все зараженные растения
определенной болезнью. Высокий recall важен для своевременного обнаружения –
пропущенный больной экземпляр (ложно-негативный) может стоить дорого.
• F1-score – гармоническое среднее precision и recall, дается как $2 \cdot \frac{precision \cdot
recall}{precision + recall}$. F1 уместно использовать для оценки баланса между precision и
recall.
В нашем эксперименте на сбалансированном датасете все эти метрики оказались высокими и
близкими друг к другу. Однако в реальности возможны ситуации, когда оптимизация разных
метрик конфликтует. Например, чтобы повысить precision, модель может стать
сверхконсервативной и реже "сигнализировать" о болезни – тогда она будет пропускать
некоторые реальные случаи (низкий recall). Или наоборот, чтобы поймать все случаи
(recall=100%), она начнет слишком часто срабатывать (в том числе на здоровых листьях), снижая
precision. В агротехнике, вероятно, важнее не пропустить болезнь (т.е. высокий recall), однако
большое число ложных срабатываний тоже нежелательно (фермер устает от ложных тревог).
Поэтому нужен баланс, и F1-score помогает его измерить.
Наш ResNet50, обученный на полном наборе PlantVillage, показал Precision ≈ 0.99 и Recall ≈ 0.99
(усредненно по классам), что свидетельствует о сбалансированной производительности. При
наличии перекоса в данных или различной сложности классов следовало бы дополнительно
смотреть на метрики для каждого класса. Например, часто встречается ситуация:
распространенные болезни модель ловит хорошо (высокие precision и recall), а редкие – хуже. В
таком случае целесообразно целенаправленно увеличить количество обучающих примеров
редких болезней или применить стратифицированные метрики (например, macro-averaged F1)
при оптимизации.
Проблема обобщения и реальное качество. Как отмечалось в обзоре литературы, высокая
точность на тесте, идентичном обучающим данным, не гарантирует аналогичного качества в
боевых условиях. В нашем случае 98–99% accuracy относится к относительно однородным
изображениям листьев на нейтральном фоне. При переносе модели на фотографии из поля (где
фон сложный, листья могут быть частично закрыты или повреждены чем-то еще) точность
заметно снизится. Исследования показывают, что без дообучения на полевых данных качество
может упасть на десятки процентов.
Основная причина – смещение распределения данных (domain shift). Модель ResNet50
фактически выучила контекст PlantVillage: например, здоровые листья в этом наборе часто фотографировались на другом фоне, чем больные (такое бывает, если разные люди собирали
данные). Модель могла невольно запомнить, что определенный фон коррелирует с классом
"здоровый", и использовать фон как признак. В реальном же фото фон будет иным, и модель
запутается. Такой скрытый bias выявили, например, в работе T. Dechant et al. (2022): нейросеть
обращала внимание на части изображения вне самого листа, что неверно. 
Таким образом, в прикладном плане 99% точности ResNet50 – это потенциал модели при
идеальном совпадении условий. Для достижения аналогичных результатов в полевых условиях
часто применяют: 1) сбор дополнительной выборки реальных изображений и тонкую настройку
(fine-tuning) модели на них; 2) генерация синтетических данных (например, накладывание
изображений листьев на разные фоны, изменение освещения – т.е. агрессивная аугментация); 3)
использование методов domain adaptation – специальных подходов, обучающих модель
игнорировать фон, фокусироваться на областях листьев и пр. Например, одно из решений –
выделять маску листа (сегментация) и подавать в классификатор только вырезанный лист на
искусственном фоне, чтобы устранить информацию о фоне. Это, однако, требует
дополнительного шага обработки. Другой подход – добавлять в обучение примеры, где фон
намеренно изменен (перемешан между классами), чтобы модель поняла, что фон не
информативен. Современные работы комбинируют такие идеи, добиваясь повышения
устойчивости модели к артефактам и разным качествам изображений.
Влияние фона и условий съемки. Хотя на наших тестовых данных фон был однотонным, стоит
отдельно обсудить: как уже отмечалось, фон способен вводить модель в заблуждение. Если на
этапе обучения в данных есть систематическая связь между болезнью и фоном (например,
фотографии одного класса делали на белом столе, а другого – на черном), то модель может
принять эту корреляцию за причинность. В реальном применении фон будет произвольным, и
такая модель начнет ошибаться. Пример: в одной из работ по генерализации был случай, когда
модель определяла болезнь каучуконосной гевеи по наличию неба на фото – т.к. многие
изображения больных листьев делались на фоне неба, модель решила, что голубой фон –
признак болезни. Когда фон убрали (заменили на черный), та же модель неожиданно выдала
другой диагноз, хотя лист остался тем же. Это четко указывает, что сеть опиралась на фон.
Для нашего ResNet50 мы, к счастью, не видим такой проблемы на Grad-CAM – модель явно
"смотрит" на лист, а не на фон. Но если бы фон изменился на природный, неизвестно, не начнет
ли она реагировать на него. Предположительно, начнет – поэтому в боевых системах часто
стараются локализовать лист (например, с помощью сегментации или банального вырезания по
цвету) и подавать модели только область листа. В нашем эксперименте такой шаг не был нужен
из-за изначально выверенных данных, но это стоит учитывать при внедрении.
Вывод этой части: ResNet50 способна очень точно классифицировать заболевания растений,
опираясь на информативные области изображения (симптомы на листьях). Тем не менее, модель
не застрахована от ошибок в случаях, когда встречаются: (1) визуально схожие заболевания, (2)
одновременно несколько факторов поражения, (3) непривычный фон или условия (артефакты
съемки). Для повышения надежности в таких случаях требуется либо дополнительное обучение,
либо включение в контур человека-эксперта, либо использование более сложных систем
(например, сначала сегментация, потом классификация, или даже последовательная
классификация – сначала определить наличие болезни вообще, потом уточнять вид). В
следующем разделе мы обсудим вопросы надежности и устойчивости модели подробнее, в том
числе влияние артефактов и способы повышения робастности.
Этика применения ИИ в сельском хозяйстве
Внедрение искусственного интеллекта в сельское хозяйство поднимает ряд этических и
социальных вопросов. Рассмотрим основные из них применительно к задаче автоматической
диагностики болезней растений:
1. Надежность и ответственность. Когда решения принимаются на основе вывода нейросети,
возникает вопрос ответственности за ошибки. Если ИИ-система неверно диагностирует болезнь,
приведя к неправильному лечению (например, излишнему применению пестицидов или
наоборот бездействию), кто будет нести ответственность за ущерб? Разработчики системы
должны осознавать эту ответственность и стремиться минимизировать риски ошибок.
Рекомендуется, чтобы такие системы работали в связке с человеком, а не полностью
автономно. То есть, ИИ выдает рекомендацию, но окончательное решение принимает агроном
или фермер, проверив обоснование. Такой подход называется Human-in-the-loop и сейчас
считается золотым стандартом для высоко рискованных областей (медицина, автономные
автомобили, и т.д.). Важно также открыто сообщать пользователям о возможной погрешности
системы, чтобы не создавать ложного чувства гарантии. Прозрачность в оценке качества
(например, "точность ~95%, возможны ошибки") – залог того, что фермер не примет решение
слепо, а отнесется критически и проверит при необходимости.
2. Справедливость и отсутствие дискриминации. В агросекторе проблема bias (смещения)
проявляется немного иначе, чем, скажем, в социальных данных, но тоже может иметь место.
Например, система, обученная на данных одной географии, может хуже работать в другой – по
причинам климатических особенностей, отличий в сортах растений, условиях выращивания.
Если ИИ-сервис глобально внедряется, важно позаботиться о представительности обучающих
данных, чтобы не получилось, что он хорошо работает для стран Европы, но плохо для Африки
(где могут быть другие распространенные болезни или другие визуальные проявления). Это
можно считать этическим вопросом равенства доступа: всем ли фермерам технология приносит
пользу одинаково? Решение – включать разнообразные данные в обучение, либо локально
дообучать модели под конкретные регионы.
3. Прозрачность и объяснимость (Explainability). Как мы обсуждали, интерпретируемость
очень важна для доверия пользователей. С этической точки зрения, фермер имеет право знать,
почему алгоритм решил, что его растения больны именно этой болезнью. "Черный ящик",
дающий указания без объяснений, может вызвать обоснованные подозрения и отторжение.
Поэтому современные системы стремятся предоставлять хотя бы минимальные объяснения –
например, выделять область листа, где обнаружены симптомы, или указывать признаки, по
которым поставлен диагноз. Это сродни тому, как врач обосновывает пациенту свой диагноз.
Повышение доверия через объяснимость не только этически важно, но и практически: люди
будут скорее использовать систему, если она понятна. Согласно недавним публикациям,
отсутствие объяснений результатов глубинных моделей в агро может привести к тому, что
специалисты не будут им доверять. Поэтому этический императив – делать системы
максимально прозрачными в рамках возможного.
4. Замещение рабочих мест и роль человека. Автоматизация диагностики болезней может
вызвать опасения, что роль агрономов и фитопатологов будет умалена. Однако реальность
такова, что квалифицированных агрономов не хватает, особенно в отдаленных регионах. ИИ-
система скорее выступает в роли помощника, способного закрыть этот пробел, чем конкурента. В
идеале она снимает рутинную нагрузку (осмотр тысяч растений) и позволяет экспертам
сфокусироваться на подтверждении и решении сложных случаев. Этический подход здесь –
позиционировать и использовать AI как инструмент для расширения возможностей специалиста
(augmented intelligence), а не как замену ему. Тогда технология не встретит сопротивления
сообщества, наоборот – профессионалы будут заинтересованы пользоваться ей как
дополнительным источником информации.
5. Конфиденциальность данных. В контексте сельского хозяйства это менее остро, чем в
медицине или финансовой сфере, но все же: данные фермеров (например, фотографии их полей,
сведения о заболеваниях) – это их собственность. Если сервис собирает такие данные для
анализа, нужно обеспечить их защиту и анонимность при агрегировании. Кроме того, если на
изображениях есть геопривязка, это коммерчески чувствительная информация (скажем, где
вспышка болезни – конкуренты или вредители могут использовать). Поэтому разработчики
должны соблюдать лучшие практики в области хранения и использования данных, получать
информированное согласие пользователей на то, как их данные будут применяться (например,
для улучшения модели).
6. Экологические и социальные последствия. Широкое внедрение диагностики болезней
может повлечь косвенные эффекты. Положительный сценарий: раннее выявление болезней
позволит сократить использование химических средств защиты (ведь если болезнь поймана
вовремя, достаточно точечного вмешательства, а не тотального опрыскивания), что полезно для
экологии и здоровья людей. Отрицательный сценарий (маловероятный, но надо упомянуть):
если система склонна перестраховываться, фермер может чаще применять пестициды "на всякий
случай". Важно обучать пользователей правильной интерпретации результатов: например,
высокий recall модели – это хорошо, но не повод сразу применять химию, нужно убедиться в диагнозе. В идеале, систему стоит интегрировать с рекомендациями устойчивого земледелия:
если болезнь обнаружена, советовать не только хим. обработку, но и агротехнические меры
(удалить зараженные листья, применить биоконтроль и т.п.). Это выходит за рамки чисто ML-
задачи, но относится к этике – разработчики несут ответственность за влияние своего продукта
на окружающую среду.
Резюмируя, этичное применение ИИ в сельском хозяйстве подразумевает честность,
прозрачность и помощь, а не замену. Технология должна приносить пользу фермерам и
экосистеме, а не навязывать риски или несправедливость. Соблюдение этих принципов повысит
доверие к системам диагностики и ускорит их распространение, что в итоге выгодно всем.
доверие к системам диагностики и ускорит их распространение, что в итоге выгодно всем.
Устойчивость модели к артефактам и качеству
изображений
Robustness (устойчивость) моделей компьютерного зрения – критический параметр, особенно
при выходе из лаборатории в реальный мир. В контексте классификации болезней растений, под
устойчивостью понимается способность модели правильно работать при изменениях входных
данных, не представленных явно в обучающей выборке. Рассмотрим несколько видов
артефактов и факторов, влияющих на качество снимков, и как ResNet50 справляется с ними, а
также подходы к повышению устойчивости.
1. Сложный фон и посторонние объекты. Как уже подробно обсуждалось, фон фотографии
может существенно влиять на вывод модели. Наша ResNet50 обучалась на изображениях листьев
на простом фоне и в случае такого же фона показывает устойчивость (Grad-CAM подтверждает,
что фон игнорируется). Но стоит поместить лист в натуральную среду – на дереве, среди других
листьев, на земле – и задача усложняется. Модель должна отделить лист от фона (по сути,
выполнить задачу сегментации в уме) и сконцентрироваться на признаках болезни. Не каждая
модель справится: некоторые будут "путаться" в фоне, особенно если фон содержит элементы,
похожие на признаки болезней (например, пятна света и тени могут напоминать пятна
инфекции). Простой пример артефакта – тень от другого листа на обследуемом листе:
человеческий глаз обычно отличит тень от пятна болезни, а модель может посчитать темное
пятно тени за симптом. Устойчивость к фону и посторонним предметам достигается путем
разнообразия обучающих данных (разные фоны, наличие шумов) и использованием методов
внимания, фокусировки на объекте. Например, современные подходы вводят в архитектуру
блоки внимания, которые могут научиться фильтровать фон. Для ResNet50 возможно дополнение
в виде attention gating или использование предобработки – алгоритмического выделения контура
листа. В практике реализации приложений диагностики часто сначала сегментируют лист, а уже
потом подают в классификатор – это сильно повышает надежность, так как устраняется
переменная фона. Еще один прием – обучение с окклюзиями: в процессе тренировки на
изображениях специально закрашиваются случайные области или накладываются "помехи",
чтобы заставить модель быть менее чувствительной к отсутствующим фрагментам и артефактам.
2. Качество изображения: размытость, шум, низкое разрешение. В полевых условиях снимки
могут получаться не идеальными. Смартфон может сфокусироваться не точно, из-за чего
изображение листа чуть размыто. Или фото сделано в сумерках – тогда много шумов и слабый
контраст. ResNet50, как глубокая сеть, до некоторой степени устойчива к небольшим ухудшениям
качества, потому что она училась на миллионах изображений с разным качеством
(предобучивание на ImageNet). Однако сильные искажения могут привести к сбою в
распознавании. Например, сильная размытие (blur) сглаживает мелкие детали – если болезнь
характеризуется мелкими пятнами, их может просто не быть видно модели. Добавление легкого
гауссова размытия или шумов в аугментациях при обучении может помочь подготовить модель к
таким случаям. В литературе описаны тесты, когда на изображение накладывали имитацию
различных погодных условий (дождевые капли, туман) – качество классификации падало, но
умеренно, если модель видела подобное на трейне. Устойчивость ResNet50 к подобным
искажениям лучше, чем у более ранних моделей, благодаря архитектурной избыточности: сеть
широкая, многие фильтры могут подхватить сигнал даже если он частично утерян. Тем не менее,
рекомендуется: (а) получать как можно более четкие снимки (это задача пользователя), (б)
использовать при обучении приемы типа motion blur augmentation, color jitter, чтобы модель не
была слишком узко заточена на студийное качество.
3. Вариативность освещения и цвета. Лист на солнце выглядит иначе, чем тот же лист в тени:
цвет может меняться, контраст симптомов – тоже. Модель, обученная только на однотипных
условиях освещения, может воспринять, скажем, покрасневший от заката лист за заболевание
(например, вирусы часто вызывают покраснение, и вечерний свет может дать красноватый
оттенок здоровому листу). Чтобы повысить устойчивость, в тренировку включают аугментации
яркости, контраста, цветового тона. Предобученные сети уже частично инвариантны к таким
изменениям, но в критичных местах (например, болезнь проявляется желтизной листа – как
отличить ее от желтизны из-за сухости или осеннего увядания?) требуется явное внимание. В
перспективе, возможно, модели будут дополняться данными от специальных сенсоров,
например, многоспектральные камеры, которые менее чувствительны к видимому освещению, а
анализируют инфракрасный отклик листа – это увеличит надежность. Но в рамках RGB-фото
добиваются robust-эффекта расширением данных и normalization-подходами. Зачастую, чтобы
модель не привязывалась к абсолютному значению цвета, используют нормирование по
среднему и дисперсии изображения или преобразование в цветовые пространства, где
отдельные компоненты отделены (например, HSV, Lab).
4. Новые или невиданные данные (out-of-distribution). Реальный мир подкидывает сюрпризы:
может появиться новая болезнь, которой не было в обучающей выборке, или вариант болезни с
нетипичными симптомами. ResNet50, как и любая классификатор, в такой ситуации все равно
выдаст какой-то из известных ей классов – у нее нет варианта "Unknown". Это потенциально
опасно: модель может уверенно ошибаться, вводя пользователя в заблуждение. Устойчивость к
неизвестным классам – отдельная задача (out-of-distribution detection). Простое решение – если
уверенность модели низкая (например, ни один класс не получил высокий softmax-скор), то
сигнализировать об этом: "Не уверена в диагнозе, требуется эксперт". Это лучше, чем ложный
диагноз. В нашей реализации мы не закладывали такого механизма, но в приложениях он
желателен. Также можно обучать модель обнаруживать аномалии: например, добавить класс
"другое" со случайными повреждениями листьев или разными артефактами, чтобы модель
училась распознавать, когда изображение не подходит ни к одному из известных заболеваний.
5. Атаки на модель (adversarial). Теоретически, можно представить злоумышленника, который
захочет обмануть агроскаутинговую модель – например, распылить на листья что-то, что
имитирует болезнь, чтобы конкурент подумал о вспышке и обработал лишний раз поле
(потратив ресурсы). Хотя это экзотический сценарий, исследования по adversarial-устойчивости
нейросетей показывают, что небольшие специально сделанные изменения пикселей могут
радикально менять предсказание. ResNet50 уязвима к adversarial examples, как и другие CNN. Для
защиты существуют методы robust training (обучение на зашумленных или атакованных
примерах), использование ансамблей, применение специальных слоев детекции атак. В
сельском хозяйстве пока атаки не актуальны, но на будущее, если ИИ широко войдет, нельзя
исключать и такие угрозы (например, вредоносный компьютерный вирус, изменяющий
поступающие с дрона снимки, чтобы ИИ неверно оценивал здоровье посевов). Это скорее вопрос
кибербезопасности инфраструктуры.
Подводя итог: нашу модель ResNet50 можно считать достаточно устойчивой к небольшим
отклонениям качества и фона, что подтверждается как встроенными свойствами архитектуры,
так и экспериментальными результатами (в контролируемых условиях она не чувствительна к
фону, правильно выделяет нужные области). Но при значительных артефактах (сложный фон,
сильный шум/размытие, новое распределение данных) надежность без специальных мер падает.
Для практического применения следует предусмотреть расширение данных, дополнительные
модули (сегментацию листьев, контроль уверенности) и непрерывный процесс адаптации
модели к новым данным. Устойчивость – не статичное свойство, а то, что достигается
постоянным улучшением системы по мере поступления обратной связи от пользователей и
появления новых сценариев.
Интерпретируемость модели и доверие пользователей
Как уже упоминалось, интерпретируемость (explainability) играет ключевую роль в принятии
ИИ-системы пользователями. Разберем, какие методы повышают прозрачность ResNet50 в
нашей задаче и как это связано с доверием фермеров и агрономов к технологии.
1. Визуальные объяснения (Grad-CAM и др.). В нашем эксперименте мы использовали Grad-
CAM, чтобы подсветить области изображения, наиболее значимые для модели. Такие
визуализации легко понятны человеку: посмотрев на раскрашенный лист, агроном видит, что
модель "смотрит" на определенные пятна. Если эти пятна действительно являются симптомами
болезни, эксперт соглашается с моделью и доверие усиливается. Если же модель выделяет что-то
явно не связанное (например, край листа или фон) – это сигнал о возможной ошибке или
переобучении. В литературе зафиксированы случаи, когда благодаря Grad-CAM люди
обнаруживали несостоятельность модели: например, модель определяла болезнь винограда по
наличию кусочка белой этикетки на фото (которая случайно присутствовала на большинстве
больных образцов). Такое поведение сразу видно на Grad-CAM – он светится там, где этикетка, а
не на пятнах листа. Выявив это, разработчики могут исправить данные и модель. Таким образом,
визуальные интерпретации служат не только для повышения доверия пользователя, но и как
инструмент разработчика для отладки модели.
В нашем случае Grad-CAM показал ожидаемое поведение на тестовых данных – это хороший
признак. Однако Grad-CAM тоже имеет ограничения: он показывает где важные признаки, но не
говорит какие именно признаки видит модель (цвет, форма, текстура?). Поэтому появляются более
продвинутые методы.
2. Концептуальные объяснения. Современные исследования предлагают объяснять решения
модели через осмысленные человеку концепты. Например, для болезней растений такими
концептами могут быть: "пожелтение краев листа", "мозаичная окраска", "порошкообразный
налет", "дырки в листьях" и т.д. В упомянутом методе ACE (Automated Concept-based Explanation)
пытаются автоматически выделить такие повторяющиеся паттерны в активах модели 26 . Если, к
примеру, ACE покажет, что при диагнозе "мучнистая роса" модель опирается на концепт "белый
пушистый налет", специалистам сразу понятно – да, действительно мучнистая роса
характеризуется налетом. А если ACE выявит какой-то непонятный концепт (скажем, "темный угол
изображения") как важный – это повод насторожиться. Пока эти методы далеки от интеграции в
практические приложения, но тенденция такова, что объяснения станут все более
семантичными, "человеко-читаемыми".
3. Приложение: как донести объяснение до пользователя. Даже лучший метод объяснения
бесполезен, если интерфейс системы не передает эту информацию фермеру. Нужно, чтобыпользовательский интерфейс (мобильное приложение или программа) вместе с результатом
показывал и объяснение. Например: "Обнаружена болезнь X (75% уверенность). Признаки:
желтые пятна с темной каймой по центру листа." – плюс изображение с выделенными пятнами.
Тогда пользователь, видя описание и визуализацию, вспомнит, что действительно эта болезнь
так проявляется, и согласится с выводом. Если же ИИ просто скажет "болезнь X", а человек знает,
что обычно X проявляется по-другому, возникнет конфликт и потеря доверия. Поэтому
локальные знания экспертов должны быть в системе – хотя бы в виде небольшой базы
описаний болезней, чтобы вывод модели можно было сопоставить со справочной информацией.
По сути, ИИ-система должна не только называть класс, но и напоминать, какие у него симптомы,
чтобы пользователь сам сверил с листом.
4. Доверие через постепенное внедрение. В реальных проектах отмечено, что доверие к ИИ
растет, если люди видят, как система ошибается и исправляется. Поэтому важна обратная связь:
если фермер не согласен с диагнозом, он должен иметь возможность отметить это. Разработчики
или алгоритмы активного обучения затем используют эти примеры для дообучения модели, и в
обновлениях система уже не повторяет ту же ошибку. Видя этот прогресс (например, приложение
сообщает: "мы улучшили распознавание болезни Y с учетом ваших данных, теперь точность
выше"), пользователь начинает доверять, потому что вовлечен в процесс обучения. Это
превращает изначально чуждый ИИ в своего рода партнера, которого можно научить –
психологически это легче приемлемо.
5. Ограничения интерпретируемости. С другой стороны, есть опасность: предоставляя
объяснение, можно создать ложное ощущение понимания. Например, Grad-CAM подсветил
область – фермер думает "понятно, смотрит на пятна". Но он не знает, почему именно эти пиксели
важны – вдруг там еле заметный узор, неочевидный человеку. То есть объяснения нейросетей –
это скорее подсказки, они не дают 100% прозрачности, как, скажем, четкое правило. Поэтому в
высокоответственных решениях иногда предпочитают более простые, но объяснимые модели
(например, решающие деревья, линейные классификаторы с несколькими признаками). Однако
в нашем случае упростить модель, сохранив точность, сложно; поэтому упор делается на пост-хок
объяснения, как Grad-CAM.
6. Построение культуры доверия. Отдельно стоит упомянуть, что кроме технических методов,
доверие пользователей требует просветительской работы. Фермерам нужно объяснять
возможности и ограничения системы, обучать их интерпретации результатов. К примеру, чтобы
пользователь не паниковал от каждого предупреждения модели, можно включить обучающий
модуль: "Если уверенность низкая или симптомы неопределенные – обратитесь к специалисту".
Такие подсказки можно выдавать контекстно. Это уже уровень UI/UX и образования, но он
критичен. Без этого даже самые интерпретируемые алгоритмы могут быть неправильно поняты.
В заключение, можно сказать, что интерпретируемость – необходимое условие для успешного
внедрения ИИ-диагностики в сельском хозяйстве. Наш эксперимент с Grad-CAM подтвердил, что
ResNet50 в основном принимает решения на основании осмысленных визуальных признаков, а
не случайного шума, что уже повышает доверие.
